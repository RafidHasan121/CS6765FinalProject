{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd1d0a6b",
   "metadata": {},
   "source": [
    "# Spam Detection\n",
    "\n",
    "This notebook contains ONLY tested, working code.\n",
    "All redundancy removed, all graphs tested and confirmed working.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160f058f",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aea7b5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b6bcf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Centralized Ollama inference + robust label extraction\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "\n",
    "def extract_label(output: str) -> str:\n",
    "    \"\"\"Extracts a canonical label 'SPAM' or 'HAM' from model text output.\n",
    "    Tries reversed-line scan, token check, LABEL_0/LABEL_1, numeric fallbacks, then None.\"\"\"\n",
    "    if output is None:\n",
    "        return None\n",
    "    out_up = output.upper()\n",
    "    # 1) scan lines from bottom for standalone token\n",
    "    for line in reversed(output.splitlines()):\n",
    "        l = line.strip().upper()\n",
    "        if l in (\"SPAM\", \"HAM\"):\n",
    "            return l\n",
    "        # token-level check (e.g. 'Label: HAM')\n",
    "        tokens = [t.strip(\" :.,\\\"'\\t\") for t in l.split()]\n",
    "        for tok in tokens:\n",
    "            if tok in (\"SPAM\", \"HAM\"):\n",
    "                return tok\n",
    "            if tok in (\"LABEL_0\", \"LABEL_1\"):\n",
    "                return \"SPAM\" if tok.endswith(\"1\") else \"HAM\"\n",
    "            if tok in (\"0\",\"1\"):\n",
    "                return \"SPAM\" if tok == \"1\" else \"HAM\"\n",
    "    # 2) fallback - look for LABEL_0/LABEL_1 anywhere\n",
    "    if \"LABEL_1\" in out_up:\n",
    "        return \"SPAM\"\n",
    "    if \"LABEL_0\" in out_up:\n",
    "        return \"HAM\"\n",
    "    # 3) fallback - last occurrence of SPAM/HAM in text\n",
    "    if \"SPAM\" in out_up:\n",
    "        return \"SPAM\"\n",
    "    if \"HAM\" in out_up:\n",
    "        return \"HAM\"\n",
    "    return None\n",
    "\n",
    "def run_ollama_model(ollama_model: str, texts, sample_size=100, timeout=60, verbose=True, seed=None, indices=None):\n",
    "    \"\"\"Run Ollama `ollama_model` on `texts` (iterable).\n",
    "    Returns: (preds_array, raw_outputs_list, indices_used) where preds are 0/1 ints (0=HAM,1=SPAM).\n",
    "    This function samples `sample_size` indices (without replacement) from texts if sample_size < len(texts).\n",
    "    You may pass `indices` to control exactly which examples are run, or `seed` for deterministic sampling.\n",
    "    \"\"\"\n",
    "    import numpy as _np\n",
    "    n = len(texts)\n",
    "    # If explicit indices provided, use them (assumed to index into `texts`)\n",
    "    if indices is not None:\n",
    "        indices = _np.asarray(indices, dtype=int)\n",
    "    else:\n",
    "        # Determine indices via sampling\n",
    "        if sample_size is None or sample_size >= n:\n",
    "            indices = _np.arange(n)\n",
    "        else:\n",
    "            if seed is not None:\n",
    "                rng = _np.random.default_rng(seed)\n",
    "                indices = rng.choice(n, sample_size, replace=False)\n",
    "            else:\n",
    "                indices = _np.random.choice(n, sample_size, replace=False)\n",
    "    selected = [texts[i] for i in indices]\n",
    "    preds = []\n",
    "    raw_outputs = []\n",
    "    for i, text in enumerate(selected):\n",
    "        if verbose and i % 50 == 0:\n",
    "            print(f\"  Running {ollama_model}: {i}/{len(selected)}\")\n",
    "        prompt = f\"Classify this email as SPAM or HAM (not spam). Answer with only SPAM or HAM.\\n\\nEmail: {text[:1000]}\"\n",
    "        try:\n",
    "            result = subprocess.run([\"ollama\", \"run\", ollama_model, prompt],\n",
    "                                     timeout=timeout, capture_output=True, text=True, input=\"\")\n",
    "            output = (result.stdout or result.stderr or \"\").strip()\n",
    "            raw_outputs.append(output)\n",
    "            label = extract_label(output)\n",
    "            pred = 1 if label == \"SPAM\" else 0\n",
    "            preds.append(pred)\n",
    "        except subprocess.TimeoutExpired:\n",
    "            print(f\"  Timeout for sample {i}; marking HAM (0) and continuing\")\n",
    "            raw_outputs.append(\"\")\n",
    "            preds.append(0)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error for sample {i}: {e}; marking HAM (0) and continuing\")\n",
    "            raw_outputs.append(\"\")\n",
    "            preds.append(0)\n",
    "    return _np.array(preds), raw_outputs, indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "604fd620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded CSV with 33716 rows and 5 columns\n"
     ]
    }
   ],
   "source": [
    "# Load CSV data\n",
    "csv_path = Path('enron_spam_data_to_use.csv')\n",
    "if csv_path.exists():\n",
    "    df_original = pd.read_csv(csv_path)\n",
    "    # Normalize label column to lower-case and map numeric labels if present\n",
    "    if 'Spam/Ham' in df_original.columns:\n",
    "        df_original['Spam/Ham'] = df_original['Spam/Ham'].astype(str).str.strip().str.lower()\n",
    "        # Map common numeric encodings to textual labels\n",
    "        df_original['Spam/Ham'] = df_original['Spam/Ham'].replace({'0':'ham','1':'spam'})\n",
    "    print(f\"✓ Loaded CSV with {df_original.shape[0]} rows and {df_original.shape[1]} columns\")\n",
    "else:\n",
    "    print(\"✗ CSV file not found\")\n",
    "    df_original = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550c0bd3",
   "metadata": {},
   "source": [
    "## 2. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d5b684e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (33716, 5)\n",
      "\n",
      "Columns: ['Unnamed: 0', 'Subject', 'Message', 'Spam/Ham', 'Date']\n",
      "\n",
      "Data Types:\n",
      "Unnamed: 0     int64\n",
      "Subject       object\n",
      "Message       object\n",
      "Spam/Ham      object\n",
      "Date          object\n",
      "dtype: object\n",
      "\n",
      "Missing Values:\n",
      "Unnamed: 0     0\n",
      "Subject        0\n",
      "Message       52\n",
      "Spam/Ham       0\n",
      "Date           0\n",
      "dtype: int64\n",
      "\n",
      "Class Distribution:\n",
      "Spam/Ham\n",
      "spam    17171\n",
      "ham     16545\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 3 rows:\n",
      "   Unnamed: 0                       Subject  \\\n",
      "0           0  christmas tree farm pictures   \n",
      "1           1      vastar resources , inc .   \n",
      "2           2  calpine daily gas nomination   \n",
      "\n",
      "                                             Message Spam/Ham        Date  \n",
      "0                                                NaN      ham  1999-12-10  \n",
      "1  gary , production from the high island larger ...      ham  1999-12-13  \n",
      "2             - calpine daily gas nomination 1 . doc      ham  1999-12-14  \n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset Shape: {df_original.shape}\")\n",
    "print(f\"\\nColumns: {df_original.columns.tolist()}\")\n",
    "print(f\"\\nData Types:\\n{df_original.dtypes}\")\n",
    "print(f\"\\nMissing Values:\\n{df_original.isnull().sum()}\")\n",
    "print(f\"\\nClass Distribution:\\n{df_original['Spam/Ham'].value_counts()}\")\n",
    "print(f\"\\nFirst 3 rows:\")\n",
    "print(df_original.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aee8bc6",
   "metadata": {},
   "source": [
    "## 3. Train-Dev-Test Split (80-10-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b496a4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after removing null messages: 33664 rows\n",
      "\n",
      "✓ Dataset shuffled with random permutation\n",
      "\n",
      "Train set: 26931 samples (80.0%)\n",
      "Dev set: 3366 samples (10.0%)\n",
      "Test set: 3367 samples (10.0%)\n",
      "\n",
      "Class balance verification:\n",
      "\n",
      "Overall distribution:\n",
      "  Spam/Ham\n",
      "spam    17171\n",
      "ham     16493\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Train class distribution:\n",
      "  Spam/Ham\n",
      "spam    13737\n",
      "ham     13194\n",
      "Name: count, dtype: int64\n",
      "  Percentages: Spam/Ham\n",
      "spam    51.01\n",
      "ham     48.99\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Dev class distribution:\n",
      "  Spam/Ham\n",
      "spam    1717\n",
      "ham     1649\n",
      "Name: count, dtype: int64\n",
      "  Percentages: Spam/Ham\n",
      "spam    51.01\n",
      "ham     48.99\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Test class distribution:\n",
      "  Spam/Ham\n",
      "spam    1717\n",
      "ham     1650\n",
      "Name: count, dtype: int64\n",
      "  Percentages: Spam/Ham\n",
      "spam    50.99\n",
      "ham     49.01\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing messages\n",
    "df = df_original.dropna(subset=['Message']).copy()\n",
    "print(f\"Dataset after removing null messages: {df.shape[0]} rows\\n\")\n",
    "\n",
    "# Reset index to ensure random access\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Shuffle the entire dataset first to eliminate any ordering bias\n",
    "np.random.seed(42)\n",
    "shuffled_indices = np.random.permutation(len(df))\n",
    "df = df.iloc[shuffled_indices].reset_index(drop=True)\n",
    "\n",
    "print(\"✓ Dataset shuffled with random permutation\\n\")\n",
    "\n",
    "# Combine Subject and Message as text features\n",
    "df['text'] = df['Subject'].astype(str) + \" \" + df['Message'].astype(str)\n",
    "X = df[['text']]\n",
    "y = df['Spam/Ham']\n",
    "\n",
    "# First split: 80% train, 20% temp (dev + test) with stratification and randomization\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y, shuffle=True\n",
    ")\n",
    "\n",
    "# Second split: Split temp into 50-50 (dev and test) with stratification and randomization\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp, shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Dev set: {X_dev.shape[0]} samples ({X_dev.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nClass balance verification:\")\n",
    "print(f\"\\nOverall distribution:\")\n",
    "print(f\"  {y.value_counts()}\")\n",
    "\n",
    "print(f\"\\nTrain class distribution:\")\n",
    "print(f\"  {y_train.value_counts()}\")\n",
    "print(f\"  Percentages: {(y_train.value_counts() / len(y_train) * 100).round(2)}\")\n",
    "\n",
    "print(f\"\\nDev class distribution:\")\n",
    "print(f\"  {y_dev.value_counts()}\")\n",
    "print(f\"  Percentages: {(y_dev.value_counts() / len(y_dev) * 100).round(2)}\")\n",
    "\n",
    "print(f\"\\nTest class distribution:\")\n",
    "print(f\"  {y_test.value_counts()}\")\n",
    "print(f\"  Percentages: {(y_test.value_counts() / len(y_test) * 100).round(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba510b8",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering: Unigram, Bigram, Mix, and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65141b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating feature vectors...\n",
      "\n",
      "✓ Unigram: (26931, 5000)\n",
      "✓ Bigram: (26931, 5000)\n",
      "✓ Mix (1-2gram): (26931, 5000)\n",
      "✓ TF-IDF (1-2gram): (26931, 5000)\n",
      "\n",
      "✓ Feature engineering completed\n"
     ]
    }
   ],
   "source": [
    "# Extract text from dataframes\n",
    "X_train_text = X_train['text'].astype(str)\n",
    "X_dev_text = X_dev['text'].astype(str)\n",
    "X_test_text = X_test['text'].astype(str)\n",
    "\n",
    "print(\"Creating feature vectors...\\n\")\n",
    "\n",
    "# 1. Unigram (single words)\n",
    "vectorizer_unigram = CountVectorizer(ngram_range=(1, 1), max_features=5000)\n",
    "X_train_unigram = vectorizer_unigram.fit_transform(X_train_text)\n",
    "X_dev_unigram = vectorizer_unigram.transform(X_dev_text)\n",
    "X_test_unigram = vectorizer_unigram.transform(X_test_text)\n",
    "print(f\"✓ Unigram: {X_train_unigram.shape}\")\n",
    "\n",
    "# 2. Bigram (word pairs)\n",
    "vectorizer_bigram = CountVectorizer(ngram_range=(2, 2), max_features=5000)\n",
    "X_train_bigram = vectorizer_bigram.fit_transform(X_train_text)\n",
    "X_dev_bigram = vectorizer_bigram.transform(X_dev_text)\n",
    "X_test_bigram = vectorizer_bigram.transform(X_test_text)\n",
    "print(f\"✓ Bigram: {X_train_bigram.shape}\")\n",
    "\n",
    "# 3. Mix of Unigram and Bigram\n",
    "vectorizer_mix = CountVectorizer(ngram_range=(1, 2), max_features=5000)\n",
    "X_train_mix = vectorizer_mix.fit_transform(X_train_text)\n",
    "X_dev_mix = vectorizer_mix.transform(X_dev_text)\n",
    "X_test_mix = vectorizer_mix.transform(X_test_text)\n",
    "print(f\"✓ Mix (1-2gram): {X_train_mix.shape}\")\n",
    "\n",
    "# 4. TF-IDF weighted features\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_text)\n",
    "X_dev_tfidf = tfidf_vectorizer.transform(X_dev_text)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_text)\n",
    "print(f\"✓ TF-IDF (1-2gram): {X_train_tfidf.shape}\")\n",
    "\n",
    "# Store features in a dictionary\n",
    "features = {\n",
    "    'unigram': (X_train_unigram, X_dev_unigram, X_test_unigram),\n",
    "    'bigram': (X_train_bigram, X_dev_bigram, X_test_bigram),\n",
    "    'mix': (X_train_mix, X_dev_mix, X_test_mix),\n",
    "    'tfidf': (X_train_tfidf, X_dev_tfidf, X_test_tfidf)\n",
    "}\n",
    "\n",
    "print(\"\\n✓ Feature engineering completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4028873a",
   "metadata": {},
   "source": [
    "## 5. Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bbd3ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression models with different features...\n",
      "\n",
      "Training with UNIGRAM features...\n",
      "  Accuracy: 0.9994 | F1 (macro): 0.9994\n",
      "\n",
      "Training with BIGRAM features...\n",
      "  Accuracy: 0.9994 | F1 (macro): 0.9994\n",
      "\n",
      "Training with MIX features...\n",
      "  Accuracy: 0.9997 | F1 (macro): 0.9997\n",
      "\n",
      "Training with TFIDF features...\n",
      "  Accuracy: 0.9991 | F1 (macro): 0.9991\n",
      "\n",
      "======================================================================\n",
      "LOGISTIC REGRESSION - RESULTS SUMMARY\n",
      "======================================================================\n",
      "\n",
      "UNIGRAM:\n",
      "  Accuracy: 0.9994\n",
      "  Precision (macro): 0.9994\n",
      "  Recall (macro): 0.9994\n",
      "  F1-Score (macro): 0.9994\n",
      "\n",
      "BIGRAM:\n",
      "  Accuracy: 0.9994\n",
      "  Precision (macro): 0.9994\n",
      "  Recall (macro): 0.9994\n",
      "  F1-Score (macro): 0.9994\n",
      "\n",
      "MIX:\n",
      "  Accuracy: 0.9997\n",
      "  Precision (macro): 0.9997\n",
      "  Recall (macro): 0.9997\n",
      "  F1-Score (macro): 0.9997\n",
      "\n",
      "TFIDF:\n",
      "  Accuracy: 0.9991\n",
      "  Precision (macro): 0.9991\n",
      "  Recall (macro): 0.9991\n",
      "  F1-Score (macro): 0.9991\n"
     ]
    }
   ],
   "source": [
    "lr_results = {}\n",
    "\n",
    "print(\"Training Logistic Regression models with different features...\\n\")\n",
    "\n",
    "for feature_name, (X_tr, X_dv, X_ts) in features.items():\n",
    "    print(f\"Training with {feature_name.upper()} features...\")\n",
    "    \n",
    "    # Train model\n",
    "    lr_model = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "    lr_model.fit(X_tr, y_train)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred = lr_model.predict(X_ts)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    lr_results[feature_name] = {\n",
    "        'model': lr_model,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "    \n",
    "    print(f\"  Accuracy: {accuracy:.4f} | F1 (macro): {f1:.4f}\\n\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LOGISTIC REGRESSION - RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "for feature_name, metrics in lr_results.items():\n",
    "    print(f\"\\n{feature_name.upper()}:\")\n",
    "    print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"  Precision (macro): {metrics['precision']:.4f}\")\n",
    "    print(f\"  Recall (macro): {metrics['recall']:.4f}\")\n",
    "    print(f\"  F1-Score (macro): {metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3796fb22",
   "metadata": {},
   "source": [
    "## 6. Model 2: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dce898ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Naive Bayes models with different features...\n",
      "\n",
      "Training with UNIGRAM features...\n",
      "  Accuracy: 0.9854 | F1 (macro): 0.9854\n",
      "\n",
      "Training with BIGRAM features...\n",
      "  Accuracy: 0.9837 | F1 (macro): 0.9836\n",
      "\n",
      "Training with MIX features...\n",
      "  Accuracy: 0.9860 | F1 (macro): 0.9860\n",
      "\n",
      "Training with TFIDF features...\n",
      "  Accuracy: 0.9872 | F1 (macro): 0.9872\n",
      "\n",
      "======================================================================\n",
      "NAIVE BAYES - RESULTS SUMMARY\n",
      "======================================================================\n",
      "\n",
      "UNIGRAM:\n",
      "  Accuracy: 0.9854\n",
      "  Precision (macro): 0.9861\n",
      "  Recall (macro): 0.9852\n",
      "  F1-Score (macro): 0.9854\n",
      "\n",
      "BIGRAM:\n",
      "  Accuracy: 0.9837\n",
      "  Precision (macro): 0.9845\n",
      "  Recall (macro): 0.9833\n",
      "  F1-Score (macro): 0.9836\n",
      "\n",
      "MIX:\n",
      "  Accuracy: 0.9860\n",
      "  Precision (macro): 0.9867\n",
      "  Recall (macro): 0.9858\n",
      "  F1-Score (macro): 0.9860\n",
      "\n",
      "TFIDF:\n",
      "  Accuracy: 0.9872\n",
      "  Precision (macro): 0.9878\n",
      "  Recall (macro): 0.9870\n",
      "  F1-Score (macro): 0.9872\n"
     ]
    }
   ],
   "source": [
    "nb_results = {}\n",
    "\n",
    "print(\"Training Naive Bayes models with different features...\\n\")\n",
    "\n",
    "for feature_name, (X_tr, X_dv, X_ts) in features.items():\n",
    "    print(f\"Training with {feature_name.upper()} features...\")\n",
    "    \n",
    "    # Train model\n",
    "    nb_model = MultinomialNB()\n",
    "    nb_model.fit(X_tr, y_train)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred = nb_model.predict(X_ts)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    nb_results[feature_name] = {\n",
    "        'model': nb_model,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "    \n",
    "    print(f\"  Accuracy: {accuracy:.4f} | F1 (macro): {f1:.4f}\\n\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"NAIVE BAYES - RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "for feature_name, metrics in nb_results.items():\n",
    "    print(f\"\\n{feature_name.upper()}:\")\n",
    "    print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"  Precision (macro): {metrics['precision']:.4f}\")\n",
    "    print(f\"  Recall (macro): {metrics['recall']:.4f}\")\n",
    "    print(f\"  F1-Score (macro): {metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683a7ea7",
   "metadata": {},
   "source": [
    "## 7. Model 3: LSTM (Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba302f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for LSTM...\n",
      "\n",
      "Train sequences: (26931, 100)\n",
      "Dev sequences: (3366, 100)\n",
      "Test sequences: (3367, 100)\n",
      "\n",
      "Building LSTM model...\n",
      "Training LSTM model...\n",
      "\n",
      "======================================================================\n",
      "LSTM - RESULTS\n",
      "======================================================================\n",
      "Accuracy: 0.9973\n",
      "Precision (macro): 0.9974\n",
      "Recall (macro): 0.9973\n",
      "F1-Score (macro): 0.9973\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, SpatialDropout1D, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "print(\"Preparing data for LSTM...\\n\")\n",
    "\n",
    "# Tokenize text\n",
    "max_features = 5000\n",
    "max_length = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(X_train_text)\n",
    "\n",
    "# Convert text to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_text)\n",
    "X_dev_seq = tokenizer.texts_to_sequences(X_dev_text)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_text)\n",
    "\n",
    "# Pad sequences\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length)\n",
    "X_dev_pad = pad_sequences(X_dev_seq, maxlen=max_length)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_length)\n",
    "\n",
    "# Convert labels to binary (0 for ham, 1 for spam)\n",
    "y_train_bin = (y_train.values == 'spam').astype(int)\n",
    "y_dev_bin = (y_dev.values == 'spam').astype(int)\n",
    "y_test_bin = (y_test.values == 'spam').astype(int)\n",
    "\n",
    "print(f\"Train sequences: {X_train_pad.shape}\")\n",
    "print(f\"Dev sequences: {X_dev_pad.shape}\")\n",
    "print(f\"Test sequences: {X_test_pad.shape}\\n\")\n",
    "\n",
    "# Build LSTM model\n",
    "print(\"Building LSTM model...\")\n",
    "lstm_model = Sequential([\n",
    "    Embedding(max_features, 128),\n",
    "    SpatialDropout1D(0.2),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    LSTM(32),\n",
    "    Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train with early stopping\n",
    "print(\"Training LSTM model...\\n\")\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "history = lstm_model.fit(\n",
    "    X_train_pad, y_train_bin,\n",
    "    validation_data=(X_dev_pad, y_dev_bin),\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_pred_lstm = (lstm_model.predict(X_test_pad, verbose=0) > 0.5).astype(int).flatten()\n",
    "accuracy_lstm = accuracy_score(y_test_bin, y_pred_lstm)\n",
    "precision_lstm = precision_score(y_test_bin, y_pred_lstm, average='macro', zero_division=0)\n",
    "recall_lstm = recall_score(y_test_bin, y_pred_lstm, average='macro', zero_division=0)\n",
    "f1_lstm = f1_score(y_test_bin, y_pred_lstm, average='macro', zero_division=0)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LSTM - RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Accuracy: {accuracy_lstm:.4f}\")\n",
    "print(f\"Precision (macro): {precision_lstm:.4f}\")\n",
    "print(f\"Recall (macro): {recall_lstm:.4f}\")\n",
    "print(f\"F1-Score (macro): {f1_lstm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb714346",
   "metadata": {},
   "source": [
    "## 8. Model 4: BERT (Transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "572fd05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BERT on test set (sample)...\n",
      "\n",
      "  Processed 0/1000\n",
      "  Processed 250/1000\n",
      "  Processed 500/1000\n",
      "  Processed 750/1000\n",
      "\n",
      "======================================================================\n",
      "BERT - RESULTS (on sampled test set)\n",
      "======================================================================\n",
      "Accuracy: 0.4020\n",
      "Precision (macro): 0.3980\n",
      "Recall (macro): 0.4004\n",
      "F1-Score (macro): 0.3973\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "import torch\n",
    "\n",
    "print(\"Loading BERT model...\\n\")\n",
    "\n",
    "# Use distilbert for faster inference\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer_bert = AutoTokenizer.from_pretrained(model_name)\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Create pipeline\n",
    "bert_pipeline = TextClassificationPipeline(\n",
    "    model=bert_model, \n",
    "    tokenizer=tokenizer_bert, \n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "print(\"Evaluating BERT on test set (sample)...\\n\")\n",
    "\n",
    "# Sample test data for speed\n",
    "sample_size = min(1000, len(X_test_text))\n",
    "sample_indices = np.random.choice(len(X_test_text), sample_size, replace=False)\n",
    "X_test_sample = X_test_text.iloc[sample_indices].values\n",
    "y_test_sample = y_test_bin[sample_indices]\n",
    "\n",
    "# Get predictions\n",
    "bert_predictions = []\n",
    "for i, text in enumerate(X_test_sample):\n",
    "    if i % 250 == 0:\n",
    "        print(f\"  Processed {i}/{len(X_test_sample)}\")\n",
    "    try:\n",
    "        result = bert_pipeline(text[:512], truncation=True)\n",
    "        label = 1 if result[0]['label'] == 'LABEL_1' else 0\n",
    "        bert_predictions.append(label)\n",
    "    except:\n",
    "        bert_predictions.append(0)\n",
    "\n",
    "bert_predictions = np.array(bert_predictions)\n",
    "\n",
    "# Evaluate\n",
    "accuracy_bert = accuracy_score(y_test_sample, bert_predictions)\n",
    "precision_bert = precision_score(y_test_sample, bert_predictions, average='macro', zero_division=0)\n",
    "recall_bert = recall_score(y_test_sample, bert_predictions, average='macro', zero_division=0)\n",
    "f1_bert = f1_score(y_test_sample, bert_predictions, average='macro', zero_division=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BERT - RESULTS (on sampled test set)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Accuracy: {accuracy_bert:.4f}\")\n",
    "print(f\"Precision (macro): {precision_bert:.4f}\")\n",
    "print(f\"Recall (macro): {recall_bert:.4f}\")\n",
    "print(f\"F1-Score (macro): {f1_bert:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c804b2",
   "metadata": {},
   "source": [
    "## 9. Model 5: Gemma (via Ollama or HuggingFace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51f8ad13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if Ollama is available...\n",
      "\n",
      "✓ Ollama is available\n",
      "\n",
      "Available models:\n",
      "NAME            ID              SIZE      MODIFIED   \n",
      "gpt-oss:20b     17052f91a42e    13 GB     8 days ago    \n",
      "gemma:latest    a72c7f4d0a15    5.0 GB    9 days ago    \n",
      "\n",
      "\n",
      "Running Ollama (Gemma) inference on sampled test set...\n",
      "\n",
      "Selected indices: [3098 3129  122 2045  699  228  969 2896 1204  821 1386 2226  198  853\n",
      " 2784 1649 2250 3067 2748 1766]\n",
      "Selected labels (0=HAM,1=SPAM): [1 1 0 0 0 0 1 0 1 1 0 1 1 1 0 0 0 0 0 0]\n",
      "Selected sample texts (first 3 shown):\n",
      " - idx 3098: fw : memo : re : your work phone number hi , i am forwarding an email from a former bnp paribas colleague of mine who now works at hsbc . can you please advise ? thanks , iris - - - - - original messa\n",
      " - idx 3129: transfers from ees attached is the latest version of the cost center assignments for the transfers out of ees . these transfers will be effective july 1 , 2001 and i need to get this to hr by friday ,\n",
      " - idx 122: re : april , aspect volume @ texas city yes , until further notice . we will change the nom to match flow in order to keep the meter as balanced as possible . otherwise , it stays the same . so far , \n",
      "  Running gemma: 0/20\n",
      "\n",
      "======================================================================\n",
      "GEMMA (Ollama) - RESULTS (on sampled test set)\n",
      "======================================================================\n",
      "Accuracy: 0.5500\n",
      "Precision (macro): 0.5000\n",
      "Recall (macro): 0.5000\n",
      "F1-Score (macro): 0.4872\n",
      "\n",
      "✓ Sample predictions: ['SPAM', 'HAM', 'HAM', 'HAM', 'HAM', 'HAM', 'HAM', 'HAM', 'HAM', 'SPAM', 'HAM', 'HAM', 'HAM', 'HAM', 'HAM', 'SPAM', 'SPAM', 'HAM', 'SPAM', 'HAM'] (showing up to 20)\n",
      "\n",
      "Note: Full evaluation skipped. Ollama inference is time-intensive.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "print(\"Checking if Ollama is available...\\n\")\n",
    "\n",
    "# Test if Ollama is running\n",
    "try:\n",
    "    result = subprocess.run(['ollama', 'list'], capture_output=True, timeout=5, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"✓ Ollama is available\")\n",
    "        ollama_available = True\n",
    "        print(f\"\\nAvailable models:\\n{result.stdout}\")\n",
    "    else:\n",
    "        print(\"⚠ Ollama not accessible. Installation required.\")\n",
    "        ollama_available = False\n",
    "except:\n",
    "    print(\"⚠ Ollama not installed or not running\")\n",
    "    print(\"\\nTo use Ollama:\")\n",
    "    print(\"  1. Install from https://ollama.ai\")\n",
    "    print(\"  2. Run: ollama pull gemma\")\n",
    "    print(\"  3. Start Ollama service\")\n",
    "    ollama_available = False\n",
    "\n",
    "if ollama_available:\n",
    "    print(\"\\nRunning Ollama (Gemma) inference on sampled test set...\\n\")\n",
    "    # Sample a modest-sized subset for evaluation (adjustable)\n",
    "    sample_size = min(20, len(X_test_text))\n",
    "    # Select indices explicitly so we can inspect labels and samples before running\n",
    "    if sample_size < len(X_test_text):\n",
    "        indices = np.random.choice(len(X_test_text), sample_size, replace=False)\n",
    "    else:\n",
    "        indices = np.arange(len(X_test_text))\n",
    "\n",
    "    # Show selected indices, labels and a short preview of the selected samples\n",
    "    print(f\"Selected indices: {indices}\")\n",
    "    try:\n",
    "        print(f\"Selected labels (0=HAM,1=SPAM): {y_test_bin[indices]}\")\n",
    "    except Exception:\n",
    "        # Fallback if y_test_bin is a pandas Series\n",
    "        print(f\"Selected labels (0=HAM,1=SPAM): {np.asarray(y_test_bin)[indices]}\")\n",
    "    print(\"Selected sample texts (first 3 shown):\")\n",
    "    for idx in indices[:3]:\n",
    "        txt = X_test_text.iloc[idx] if hasattr(X_test_text, 'iloc') else X_test_text[idx]\n",
    "        print(f\" - idx {idx}: {str(txt)[:200].replace('\\n', ' ')}\")\n",
    "\n",
    "    # Run Ollama on the explicit indices (pass indices so the function doesn't resample)\n",
    "    preds, raw_outputs, indices = run_ollama_model(\"gemma\", X_test_text.values, sample_size=None, timeout=600, verbose=True, indices=indices)\n",
    "\n",
    "    # Align sample indices to label vector (y_test_bin defined earlier)\n",
    "    y_test_sample = np.asarray(y_test_bin)[indices]\n",
    "    ollama_predictions = preds\n",
    "\n",
    "    # Compute metrics for Gemma\n",
    "    accuracy_gemma = accuracy_score(y_test_sample, ollama_predictions)\n",
    "    precision_gemma = precision_score(y_test_sample, ollama_predictions, average='macro', zero_division=0)\n",
    "    recall_gemma = recall_score(y_test_sample, ollama_predictions, average='macro', zero_division=0)\n",
    "    f1_gemma = f1_score(y_test_sample, ollama_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"GEMMA (Ollama) - RESULTS (on sampled test set)\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Accuracy: {accuracy_gemma:.4f}\")\n",
    "    print(f\"Precision (macro): {precision_gemma:.4f}\")\n",
    "    print(f\"Recall (macro): {recall_gemma:.4f}\")\n",
    "    print(f\"F1-Score (macro): {f1_gemma:.4f}\")\n",
    "    print(f\"\\n✓ Sample predictions: {['SPAM' if p==1 else 'HAM' for p in ollama_predictions[:20]]} (showing up to 20)\")\n",
    "\n",
    "    print(f\"\\nNote: Full evaluation skipped. Ollama inference is time-intensive.\")\n",
    "else:\n",
    "    print(\"\\nSkipping Ollama (Gemma) evaluation until service is available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23637f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if Ollama is available...\n",
      "\n",
      "✓ Ollama is available\n",
      "\n",
      "Available models:\n",
      "NAME            ID              SIZE      MODIFIED   \n",
      "gpt-oss:20b     17052f91a42e    13 GB     8 days ago    \n",
      "gemma:latest    a72c7f4d0a15    5.0 GB    9 days ago    \n",
      "\n",
      "\n",
      "Running Ollama (GPT) inference on sampled test set...\n",
      "\n",
      "Selected indices: [3161  842  490 3040 2936 2077  462  244 3286 2418 1073 2191 1038 2928\n",
      " 2033 2081  963 3202 2244  766]\n",
      "Selected labels (0=HAM,1=SPAM): [0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 1]\n",
      "Selected sample text:\n",
      " - idx 3161: re : hello team ken : we are very excited about our alp at enron . we look forward to working with you and your team and learning about the broadband space . thursday at cacciatore ' s sounds fine with us . we will see you there at 7 : 00 p . m . enron alp team - - - - - original message - - - - - from : kenneth . parkhill @ enron . com [ mailto : kenneth . parkhill @ enron . com ] sent : tuesday , january 23 , 2001 10 : 47 am to : luigical @ rice . edu ; ghosei @ rice . edu ; ghoshr @ rice . edu ; iqbal @ rice . edu ; pravas @ rice . edu ; cwomack @ rice . edu ; barrett @ rice . edu ; uecker @ rice . edu ; loughrid @ rice . edu cc : vince . j . kaminski @ enron . com subject : hello team we are very excited to be able to welcome your alp team to enron . we are looking to working with you this semester . to kick things off , we would like to invite you to cacciatore ' s this thursday for dinner ( 1 / 25 / 01 , 7 pm ) . if you can ' t stand italian cuisine , or would like to try a diffe\n",
      " - idx 842: scheduling a meeting sally , dolores muzzy , celeste roberts ' assistant was attempting to schedule a meeting to discuss the commercial services program . the reason that dolores is trying to schedule a meeting is follows : ( 1 ) celeste and i were scheduled to speak briefly at rick ' s staff meeting on tuesday , april 11 th as we had at cliff baxter ' s on march 27 th . however , we were not going to have a significant amount of time and because the discussion may have been extensive , rick agreed that it made more sense to schedule a meeting in which the commercial services program was the sole topic of discussion . ( 2 ) you and i had exchanged voice mails on march 27 th , immediately after cliff ' s staff meeting where you indicated that you had a group of individuals who were involved in recruiting and who would like to meet with us regarding questions about the management of the program . you indicated that you would facilitate scheduling the meeting . however , given that i had \n",
      " - idx 490: fw : re ivanhoe e . s . d fyi , kim . - - - - - original message - - - - - from : frazier , perry sent : thursday , march 07 , 2002 2 : 25 pm to : lebeau , randy ; watson , kimberly ; abdmoulaie , mansoor subject : re : re ivanhoe e . s . d just a couple of additional thoughts , the cost estimate for esd mods of $ 130 , 000 will typically be , about 25 % more . the e abdmoulaie , mansoor ; frazier , perry subject : fw : re ivanhoe e . s . d here is an estimate for the upgrade to the ivanhoe esd system . please keep in mind that the hp at the location has not been in operation for several years and if it is ever required , we may be looking a major expense for that , too . ( $ 200 , 000 + or - ) - - - - - original message - - - - - from : jordan , fred sent : thursday , march 07 , 2002 7 : 24 am to : lebeau , randy subject : re ivanhoe e . s . d fyi - - - - - - - - - - - - - - - - - - - - - - forwarded by fred jordan / et & s / enron on 03 / 07 / 2002 07 : 10 am - - - - - - - - - - - - \n",
      " - idx 3040: fw : csfb independent power weekly - - issue # 41 - - - - - original message - - - - - from : stein , neil [ mailto : neil . stein @ csfb . com ] sent : monday , august 27 , 2001 7 : 32 am to : undisclosed - recipients subject : csfb independent power weekly - - issue # 41 > good morning , attached , please find the latest issue of our independent power weekly . also note that on september 10 and 11 , csfb will host a power generation supply chain conference at the plaza hotel in new york city . the power generators will speak on the morning of 9 / 11 . companies presenting include : cpn , mir , nrg , orn , rri and te . 1 . ipps rise 3 . 9 % last week our ipp composite rose 3 . 9 % , outperforming both the nasdaq ( + 2 . 7 % ) and the s & p 500 ( + 2 . 0 % ) . this was the strongest performance for our composite since the second week of july . calpine , which was up 10 . 9 % , was the strongest performer in the group . global power equipment group was the weakest performer , falling 3 \n",
      " - idx 2936: 8 : 30 am update trade counts through 8 : 30 am trade date na gas na power total trade cnt 11 / 20 / 2001 992 290 1720 11 / 19 / 2001 825 508 1968 11 / 18 / 2001 6 4 10 11 / 17 / 2001 10 6 16 11 / 16 / 2001 880 583 2203 11 / 15 / 2001 1006 523 2199 11 / 14 / 2001 731 444 2364 11 / 13 / 2001 868 527 1951 11 / 12 / 2001 878 380 1913 11 / 11 / 2001 7 2 9 11 / 10 / 2001 5 8 13 11 / 9 / 2001 615 444 1679 11 / 8 / 2001 975 489 1931 11 / 7 / 2001 877 727 2288 11 / 6 / 2001 1064 849 2463 11 / 5 / 2001 930 839 2308 11 / 4 / 2001 4 3 7 11 / 3 / 2001 2 16 18 11 / 2 / 2001 1211 576 2253 11 / 1 / 2001 984 769 2429 regional breakdown :\n",
      " - idx 2077: transfers from ees attached is the latest version of the cost center assignments for the transfers out of ees . these transfers will be effective july 1 , 2001 and i need to get this to hr by friday , june 1 , 2001 to give them time to get everything effected . i think i have incorporated all your comments , but please review one more time and make sure we have not included anyone we shouldn ' t have or excluded anyone . you ' ll note that at this point we are not forming east and west risk management cost centers . don and rogers have decided for cost management purposes to leave it consolidated at this point . once you have signed off on your groupings , rachel massey in corporate planning will be working with each of you to forecast your q 3 and q 4 cost center expense plans . please let me know asap of any changes and don ' t hesitate to call with questions . thanks wade\n",
      " - idx 462: got book and papers , thanks ! the fedex people dropped them off last week , and i ' m happily reading away . thanks ! keith baggerly\n",
      " - idx 244: fw : re ivanhoe e . s . d fyi , kim . - - - - - original message - - - - - from : frazier , perry sent : thursday , march 07 , 2002 2 : 25 pm to : lebeau , randy ; watson , kimberly ; abdmoulaie , mansoor subject : re : re ivanhoe e . s . d just a couple of additional thoughts , the cost estimate for esd mods of $ 130 , 000 will typically be , about 25 % more . the e abdmoulaie , mansoor ; frazier , perry subject : fw : re ivanhoe e . s . d here is an estimate for the upgrade to the ivanhoe esd system . please keep in mind that the hp at the location has not been in operation for several years and if it is ever required , we may be looking a major expense for that , too . ( $ 200 , 000 + or - ) - - - - - original message - - - - - from : jordan , fred sent : thursday , march 07 , 2002 7 : 24 am to : lebeau , randy subject : re ivanhoe e . s . d fyi - - - - - - - - - - - - - - - - - - - - - - forwarded by fred jordan / et & s / enron on 03 / 07 / 2002 07 : 10 am - - - - - - - - - - - - \n",
      " - idx 3286: fw : re ivanhoe e . s . d fyi , kim . - - - - - original message - - - - - from : frazier , perry sent : thursday , march 07 , 2002 2 : 25 pm to : lebeau , randy ; watson , kimberly ; abdmoulaie , mansoor subject : re : re ivanhoe e . s . d just a couple of additional thoughts , the cost estimate for esd mods of $ 130 , 000 will typically be , about 25 % more . the e abdmoulaie , mansoor ; frazier , perry subject : fw : re ivanhoe e . s . d here is an estimate for the upgrade to the ivanhoe esd system . please keep in mind that the hp at the location has not been in operation for several years and if it is ever required , we may be looking a major expense for that , too . ( $ 200 , 000 + or - ) - - - - - original message - - - - - from : jordan , fred sent : thursday , march 07 , 2002 7 : 24 am to : lebeau , randy subject : re ivanhoe e . s . d fyi - - - - - - - - - - - - - - - - - - - - - - forwarded by fred jordan / et & s / enron on 03 / 07 / 2002 07 : 10 am - - - - - - - - - - - - \n",
      " - idx 2418: re : tenaska iv i tried calling you this am but your phone rolled to someone else ' s voicemail . can you call me when you get a chance ? - - - - - original message - - - - - from : farmer , daren j . sent : thursday , january 10 , 2002 2 : 06 pm to : hill , garrick subject : re : tenaska iv rick , i ' ve had a couple of meetings today . i ' m sorry i ' m just getting back to you . i tried to call but the voice mail said that you were unavailable . so , give me a call when you get a chance . d - - - - - original message - - - - - from : hill , garrick sent : wednesday , january 09 , 2002 6 : 11 pm to : farmer , daren j . subject : re : tenaska iv i ' ll call you on thursday . . . what ' s a good time ? - - - - - original message - - - - - from : farmer , daren j . sent : wednesday , january 09 , 2002 3 : 03 pm to : hill , garrick cc : olsen , michael subject : tenaska iv rick , we need to talk about the ability of ena to continue its the current role as agent of tenaska iv . 1 ) since \n",
      " - idx 1073: summer hire molly , we would like to hire mr bhalachandra mehendale for a summer position . he is currently working on his ms finance at u . of wisconsin and is scheduled to finish december 2001 . his resume is attached . he will be available from about may 28 until the end of august . please let me know what additional info you need research to provide . regards , stinson - bhala _ resume . doc\n",
      " - idx 2191: fw : memo : re : your work phone number hi , i am forwarding an email from a former bnp paribas colleague of mine who now works at hsbc . can you please advise ? thanks , iris - - - - - original message - - - - - from : antonella . saulle @ hsbcib . com @ enron [ mailto : imceanotes - antonella + 2 esaulle + 40 hsbcib + 2 ecom + 40 enron @ enron . com ] sent : tuesday , may 22 , 2001 1 : 30 am to : mack , iris subject : memo : re : your work phone number iris i would like you to put me in contact with s / one at enron here in london that deals with weather derivatives and would be in a position to sell us options on weather derivatives ( temperature , cat ) . let me know if you are able to do that or if i need to work internally here in order to find out whom we have contacts with at enron . if you want to call me my direct line is + 44 207 336 - 2836 . alternatively i could call you but do bear in mind that i leave the office around 6 : 30 - 7 pm london time . send me an email and let\n",
      " - idx 1038: re : releases louise , thanks so much for your speedy reply . i will pass your comments on to dave walker in media relations . i included kevin because he is listed with you , greg and john on a \" management \" slide . if there are others who should be included on greg ' s core management team for the announcement , please let me know who they are and their titles . please also let me know if it is inappropriate to include kevin . if there is an org chart , that might be helpful , too . it would allow us to be as inclusive as possible without making the announcement too long . thanks again , claudia 212 - 713 - 8508 - - - - - original message - - - - - from : louise . kitchen @ enron . com [ mailto : louise . kitchen @ enron . com ] sent : tuesday , february 05 , 2002 11 : 16 pm to : robinson , claudia ; petrie , james [ ubs ] ; eber , louis [ ubs ] ; brady , penny [ ubs ] ; keily , ruth [ ubs ] ; mitchell , nikki [ ubs ] ; david . forster @ enron . com ; lloyd , andrew - d [ ubs ] ; ho\n",
      " - idx 2928: fw : re ivanhoe e . s . d fyi , kim . - - - - - original message - - - - - from : frazier , perry sent : thursday , march 07 , 2002 2 : 25 pm to : lebeau , randy ; watson , kimberly ; abdmoulaie , mansoor subject : re : re ivanhoe e . s . d just a couple of additional thoughts , the cost estimate for esd mods of $ 130 , 000 will typically be , about 25 % more . the e abdmoulaie , mansoor ; frazier , perry subject : fw : re ivanhoe e . s . d here is an estimate for the upgrade to the ivanhoe esd system . please keep in mind that the hp at the location has not been in operation for several years and if it is ever required , we may be looking a major expense for that , too . ( $ 200 , 000 + or - ) - - - - - original message - - - - - from : jordan , fred sent : thursday , march 07 , 2002 7 : 24 am to : lebeau , randy subject : re ivanhoe e . s . d fyi - - - - - - - - - - - - - - - - - - - - - - forwarded by fred jordan / et & s / enron on 03 / 07 / 2002 07 : 10 am - - - - - - - - - - - - \n",
      " - idx 2033: monday staff meeting guys - weather permitting in the texas panhandle area , i expect to be in friona , tx on monday , november 20 th , on business . provided below are some items i would have mentioned in the monday staff meeting : plains farmer ' s coop - to date , i have been able to collect approximately half of the $ 500 , 000 imbalance which plains coop owes tw . i will be meeting charles hough in friona ( friona is located 100 miles west of amarillo ) on monday to discuss the payment plan for the remaining imbalance amount in additionai to other general business matters . i discussed my action plan with legal and credit and will request full payment by january 31 , 2000 , latest date . effective febrary lst , tw will also include penalty payments with any future imbalance outside the + / - 10 % tolerance level . pogo producing - i met recently with john havard with pogo . pogo plans to spud a well in eddy county which is an offset to the eog operated well recently completed and \n",
      " - idx 2081: global risk management operations congratulations ! dc - - - - - - - - - - - - - - - - - - - - - - forwarded by danny clark / hou / ees on 01 / 18 / 2000 04 : 59 am - - - - - - - - - - - - - - - - - - - - - - - - - - - rick causey @ enron 01 / 17 / 2000 06 : 04 pm sent by : enron announcements @ enron to : all enron worldwide cc : subject : global risk management operations recognizing enron \u0001 , s increasing worldwide presence in the wholesale energy business and the need to insure outstanding internal controls for all of our risk management activities , regardless of location , a global risk management operations function has been created under the direction of sally w . beck , vice president . in this role , sally will report to rick causey , executive vice president and chief accounting officer . sally \u0001 , s responsibilities with regard to global risk management operations will mirror those of other recently created enron global functions . in this role , sally will work closely wit\n",
      " - idx 963: revised devon and co - owner availabilities for september fyi . . . . . . . . . . . . . . . . . . . . . . beverly - - - - - - - - - - - - - - - - - - - - - - forwarded by beverly beaty / hou / ect on 08 / 30 / 2000 08 : 10 am - - - - - - - - - - - - - - - - - - - - - - - - - - - enron capital & trade resources corp . from : \" steve holmes \" 08 / 29 / 2000 03 : 57 pm to : cc : subject : revised devon and co - owner availabilities for september beverly , the co - owner volumes have been updated to show a volume for comet petroleum and james d . finley under burnell n . pettus . additionally , devon ' s volume under burnell / n . pettus has also increased slightly . steve - 0900 co - owners volumes to enron . xls - enronavailso 900 revo 2 . xls\n",
      " - idx 3202: start date : 2 / 6 / 02 ; hourahead hour : 24 ; start date : 2 / 6 / 02 ; hourahead hour : 24 ; no ancillary schedules awarded . no variances detected . log messages : parsing file - - > > o : \\ portland \\ westdesk \\ california scheduling \\ iso final schedules \\ 2002020624 . txt ! ! ! general sql error . couldn ' t update ; currently locked by user ' admin ' on machine ' nahou - trdts 5 ' . table - - - - energy import / export schedule - - - - * * * final schedule not found for preferred schedule . details : trans _ type : final sc _ id : ectstnw mkt _ type : 2 trans _ date : 2 / 6 / 02 tie _ point : malin _ 5 _ rndmtn interchg _ id : enrj _ ciso _ 3000 engy _ type : firm\n",
      " - idx 2244: fw : re ivanhoe e . s . d fyi , kim . - - - - - original message - - - - - from : frazier , perry sent : thursday , march 07 , 2002 2 : 25 pm to : lebeau , randy ; watson , kimberly ; abdmoulaie , mansoor subject : re : re ivanhoe e . s . d just a couple of additional thoughts , the cost estimate for esd mods of $ 130 , 000 will typically be , about 25 % more . the e abdmoulaie , mansoor ; frazier , perry subject : fw : re ivanhoe e . s . d here is an estimate for the upgrade to the ivanhoe esd system . please keep in mind that the hp at the location has not been in operation for several years and if it is ever required , we may be looking a major expense for that , too . ( $ 200 , 000 + or - ) - - - - - original message - - - - - from : jordan , fred sent : thursday , march 07 , 2002 7 : 24 am to : lebeau , randy subject : re ivanhoe e . s . d fyi - - - - - - - - - - - - - - - - - - - - - - forwarded by fred jordan / et & s / enron on 03 / 07 / 2002 07 : 10 am - - - - - - - - - - - - \n",
      " - idx 766: transfers from ees attached is the latest version of the cost center assignments for the transfers out of ees . these transfers will be effective july 1 , 2001 and i need to get this to hr by friday , june 1 , 2001 to give them time to get everything effected . i think i have incorporated all your comments , but please review one more time and make sure we have not included anyone we shouldn ' t have or excluded anyone . you ' ll note that at this point we are not forming east and west risk management cost centers . don and rogers have decided for cost management purposes to leave it consolidated at this point . once you have signed off on your groupings , rachel massey in corporate planning will be working with each of you to forecast your q 3 and q 4 cost center expense plans . please let me know asap of any changes and don ' t hesitate to call with questions . thanks wade\n",
      "  Running gpt-oss:20b: 0/20\n",
      "\n",
      "======================================================================\n",
      "GPT (Ollama) - RESULTS (on sampled test set)\n",
      "======================================================================\n",
      "Accuracy: 0.4500\n",
      "Precision (macro): 0.2250\n",
      "Recall (macro): 0.5000\n",
      "F1-Score (macro): 0.3103\n",
      "\n",
      "✓ Sample predictions: ['HAM', 'HAM', 'HAM', 'HAM', 'HAM', 'HAM', 'HAM', 'HAM', 'HAM', 'HAM', 'HAM', 'HAM', 'HAM', 'HAM', 'HAM', 'HAM', 'HAM', 'HAM', 'HAM', 'HAM'] (showing up to 20)\n",
      "\n",
      "Note: Full evaluation skipped. Ollama inference is time-intensive.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "print(\"Checking if Ollama is available...\\n\")\n",
    "\n",
    "# Test if Ollama is running\n",
    "try:\n",
    "    result = subprocess.run(['ollama', 'list'], capture_output=True, timeout=5, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"✓ Ollama is available\")\n",
    "        ollama_available = True\n",
    "        print(f\"\\nAvailable models:\\n{result.stdout}\")\n",
    "    else:\n",
    "        print(\"⚠ Ollama not accessible. Installation required.\")\n",
    "        ollama_available = False\n",
    "except:\n",
    "    print(\"⚠ Ollama not installed or not running\")\n",
    "    print(\"\\nTo use Ollama:\")\n",
    "    print(\"  1. Install from https://ollama.ai\")\n",
    "    print(\"  2. Run: ollama pull gemma\")\n",
    "    print(\"  3. Start Ollama service\")\n",
    "    ollama_available = False\n",
    "\n",
    "if ollama_available:\n",
    "    print(\"\\nRunning Ollama (GPT) inference on sampled test set...\\n\")\n",
    "    # Sample a modest-sized subset for evaluation (adjustable)\n",
    "    sample_size = min(20, len(X_test_text))\n",
    "\n",
    "    # Choose indices explicitly so we can inspect the sample before running\n",
    "    if sample_size < len(X_test_text):\n",
    "        indices = np.random.choice(len(X_test_text), sample_size, replace=False)\n",
    "    else:\n",
    "        indices = np.arange(len(X_test_text))\n",
    "\n",
    "    # Print selected label and the sample text before running the model\n",
    "    print(f\"Selected indices: {indices}\")\n",
    "    try:\n",
    "        print(f\"Selected labels (0=HAM,1=SPAM): {y_test_bin[indices]}\")\n",
    "    except Exception:\n",
    "        print(f\"Selected labels (0=HAM,1=SPAM): {np.asarray(y_test_bin)[indices]}\")\n",
    "    print(\"Selected sample text:\")\n",
    "    for idx in indices:\n",
    "        txt = X_test_text.iloc[idx] if hasattr(X_test_text, 'iloc') else X_test_text[idx]\n",
    "        print(f\" - idx {idx}: {str(txt)[:1000].replace('\\n',' ')}\")\n",
    "\n",
    "    preds, raw_outputs, indices = run_ollama_model(\"gpt-oss:20b\", X_test_text.values, sample_size=None, timeout=600, verbose=True, indices=indices)\n",
    "    \n",
    "    # Align sample indices to label vector (y_test_bin defined earlier)\n",
    "    y_test_sample = np.asarray(y_test_bin)[indices]\n",
    "    ollama_predictions = preds\n",
    "\n",
    "    # Compute metrics for GPT model\n",
    "    accuracy_gpt = accuracy_score(y_test_sample, ollama_predictions)\n",
    "    precision_gpt = precision_score(y_test_sample, ollama_predictions, average='macro', zero_division=0)\n",
    "    recall_gpt = recall_score(y_test_sample, ollama_predictions, average='macro', zero_division=0)\n",
    "    f1_gpt = f1_score(y_test_sample, ollama_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"GPT (Ollama) - RESULTS (on sampled test set)\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Accuracy: {accuracy_gpt:.4f}\")\n",
    "    print(f\"Precision (macro): {precision_gpt:.4f}\")\n",
    "    print(f\"Recall (macro): {recall_gpt:.4f}\")\n",
    "    print(f\"F1-Score (macro): {f1_gpt:.4f}\")\n",
    "    print(f\"\\n✓ Sample predictions: {['SPAM' if p==1 else 'HAM' for p in ollama_predictions[:20]]} (showing up to 20)\")\n",
    "\n",
    "    print(f\"\\nNote: Full evaluation skipped. Ollama inference is time-intensive.\")\n",
    "else:\n",
    "    print(\"\\nSkipping Ollama (GPT) evaluation until service is available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac01008",
   "metadata": {},
   "source": [
    "## 11. Comprehensive Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f802f8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "COMPREHENSIVE MODEL RESULTS COMPARISON\n",
      "====================================================================================================\n",
      "\n",
      "              Model               Feature  Accuracy  Precision   Recall  F1-Score\n",
      "Logistic Regression               UNIGRAM  0.999406   0.999418 0.999394  0.999406\n",
      "Logistic Regression                BIGRAM  0.999406   0.999418 0.999394  0.999406\n",
      "Logistic Regression                   MIX  0.999703   0.999709 0.999697  0.999703\n",
      "Logistic Regression                 TFIDF  0.999109   0.999128 0.999091  0.999109\n",
      "        Naive Bayes               UNIGRAM  0.985447   0.986127 0.985152  0.985430\n",
      "        Naive Bayes                BIGRAM  0.983665   0.984481 0.983333  0.983644\n",
      "        Naive Bayes                   MIX  0.986041   0.986678 0.985758  0.986025\n",
      "        Naive Bayes                 TFIDF  0.987229   0.987784 0.986970  0.987215\n",
      "               LSTM    Sequence Embedding  0.997327   0.997393 0.997273  0.997326\n",
      "               BERT Transformer (Sampled)  0.402000   0.397957 0.400400  0.397333\n",
      "     Gemma (Ollama)       Gemma (Sampled)  0.550000   0.500000 0.500000  0.487179\n",
      "       GPT (Ollama)         GPT (Sampled)  0.450000   0.225000 0.500000  0.310345\n",
      "\n",
      "====================================================================================================\n",
      "TOP PERFORMING MODELS\n",
      "====================================================================================================\n",
      "\n",
      "Best Accuracy: Logistic Regression (MIX)\n",
      "  → Accuracy: 0.9997\n",
      "\n",
      "Best F1-Score (macro): Logistic Regression (MIX)\n",
      "  → F1-Score: 0.9997\n",
      "  → Accuracy: 0.9997\n",
      "\n",
      "====================================================================================================\n",
      "FEATURE ENGINEERING ANALYSIS\n",
      "====================================================================================================\n",
      "\n",
      "UNIGRAM:\n",
      "  Avg Accuracy: 0.9924\n",
      "  Avg F1-Score: 0.9924\n",
      "\n",
      "BIGRAM:\n",
      "  Avg Accuracy: 0.9915\n",
      "  Avg F1-Score: 0.9915\n",
      "\n",
      "MIX:\n",
      "  Avg Accuracy: 0.9929\n",
      "  Avg F1-Score: 0.9929\n",
      "\n",
      "TFIDF:\n",
      "  Avg Accuracy: 0.9932\n",
      "  Avg F1-Score: 0.9932\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Compile all results\n",
    "results_data = []\n",
    "\n",
    "# Logistic Regression results\n",
    "for feature_name, metrics in lr_results.items():\n",
    "    results_data.append({\n",
    "        'Model': 'Logistic Regression',\n",
    "        'Feature': feature_name.upper(),\n",
    "        'Accuracy': metrics['accuracy'],\n",
    "        'Precision': metrics['precision'],\n",
    "        'Recall': metrics['recall'],\n",
    "        'F1-Score': metrics['f1']\n",
    "    })\n",
    "\n",
    "# Naive Bayes results\n",
    "for feature_name, metrics in nb_results.items():\n",
    "    results_data.append({\n",
    "        'Model': 'Naive Bayes',\n",
    "        'Feature': feature_name.upper(),\n",
    "        'Accuracy': metrics['accuracy'],\n",
    "        'Precision': metrics['precision'],\n",
    "        'Recall': metrics['recall'],\n",
    "        'F1-Score': metrics['f1']\n",
    "    })\n",
    "\n",
    "# LSTM results\n",
    "results_data.append({\n",
    "    'Model': 'LSTM',\n",
    "    'Feature': 'Sequence Embedding',\n",
    "    'Accuracy': accuracy_lstm,\n",
    "    'Precision': precision_lstm,\n",
    "    'Recall': recall_lstm,\n",
    "    'F1-Score': f1_lstm\n",
    "})\n",
    "\n",
    "# BERT results\n",
    "results_data.append({\n",
    "    'Model': 'BERT',\n",
    "    'Feature': 'Transformer (Sampled)',\n",
    "    'Accuracy': accuracy_bert,\n",
    "    'Precision': precision_bert,\n",
    "    'Recall': recall_bert,\n",
    "    'F1-Score': f1_bert\n",
    "})\n",
    "\n",
    "# Add Gemma (Ollama) if metrics were computed\n",
    "if 'accuracy_gemma' in globals():\n",
    "    results_data.append({\n",
    "        'Model': 'Gemma (Ollama)',\n",
    "        'Feature': 'Gemma (Sampled)',\n",
    "        'Accuracy': accuracy_gemma,\n",
    "        'Precision': precision_gemma,\n",
    "        'Recall': recall_gemma,\n",
    "        'F1-Score': f1_gemma\n",
    "    })\n",
    "else:\n",
    "    print('Gemma metrics not available; skipping')\n",
    "\n",
    "# Add GPT (Ollama) if metrics were computed\n",
    "if 'accuracy_gpt' in globals():\n",
    "    results_data.append({\n",
    "        'Model': 'GPT (Ollama)',\n",
    "        'Feature': 'GPT (Sampled)',\n",
    "        'Accuracy': accuracy_gpt,\n",
    "        'Precision': precision_gpt,\n",
    "        'Recall': recall_gpt,\n",
    "        'F1-Score': f1_gpt\n",
    "    })\n",
    "else:\n",
    "    print('GPT metrics not available; skipping')\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(results_data)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"COMPREHENSIVE MODEL RESULTS COMPARISON\")\n",
    "print(\"=\"*100)\n",
    "print(f\"\\n{results_df.to_string(index=False)}\")\n",
    "\n",
    "# Best models\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"TOP PERFORMING MODELS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "if results_df.empty:\n",
    "    print('\\nNo results to summarize.')\n",
    "else:\n",
    "    best_accuracy_idx = results_df['Accuracy'].idxmax()\n",
    "    best_f1_idx = results_df['F1-Score'].idxmax()\n",
    "\n",
    "    best_accuracy = results_df.loc[best_accuracy_idx]\n",
    "    best_f1 = results_df.loc[best_f1_idx]\n",
    "\n",
    "    print(f\"\\nBest Accuracy: {best_accuracy['Model']} ({best_accuracy['Feature']})\")\n",
    "    print(f\"  → Accuracy: {best_accuracy['Accuracy']:.4f}\")\n",
    "\n",
    "    print(f\"\\nBest F1-Score (macro): {best_f1['Model']} ({best_f1['Feature']})\")\n",
    "    print(f\"  → F1-Score: {best_f1['F1-Score']:.4f}\")\n",
    "    print(f\"  → Accuracy: {best_f1['Accuracy']:.4f}\")\n",
    "\n",
    "# Feature engineering comparison\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"FEATURE ENGINEERING ANALYSIS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for feature in ['UNIGRAM', 'BIGRAM', 'MIX', 'TFIDF']:\n",
    "    feature_results = results_df[results_df['Feature'] == feature]\n",
    "    if len(feature_results) > 0:\n",
    "        avg_accuracy = feature_results['Accuracy'].mean()\n",
    "        avg_f1 = feature_results['F1-Score'].mean()\n",
    "        print(f\"\\n{feature}:\")\n",
    "        print(f\"  Avg Accuracy: {avg_accuracy:.4f}\")\n",
    "        print(f\"  Avg F1-Score: {avg_f1:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
